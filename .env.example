# ============ CHRONEX AI CONFIGURATION ============
# Copy this file to .env and fill in your values

# AI Provider Selection
# Options: openai, huggingface, ollama, default
AI_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-3.5-turbo

# Hugging Face Configuration
HF_MODEL=gpt2

# Ollama Configuration (for local models)
OLLAMA_ENDPOINT=http://localhost:11434

# AI Model Parameters
AI_TEMPERATURE=0.7
AI_MAX_TOKENS=1000

# Enable/Disable Real AI (true/false)
USE_REAL_AI=true

# Flask Configuration
PORT=5000
DEBUG=False

# Notes:
# 1. Get OpenAI API key from: https://platform.openai.com/api-keys
# 2. For Hugging Face, install: pip install transformers torch
# 3. For Ollama, download from: https://ollama.ai
# 4. If USE_REAL_AI=false, system uses default cached responses
